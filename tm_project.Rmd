---
title: "What is happening with pop music culture?"
author: "Phong Duong"
date: "2024-02-14"
output: html_document
---

# Introduction

The last 5 years have been eventful around the world. From the tumult of Brexit in 2019, to the global spread of COVID-19 pandemic in 2020, followed by respite of the 2020 Olympic game in 2021, the Russia-Ukrain conflict in 2022, and the recent record of global temperature in 2023, each year has been marked by events that have left an indelible imprint on society. These occurrences have not only shaped our external environment but have also influenced individual perceptions, behaviors, and emotional responses.

Against this backdrop of changes and upheavals, pop music emerges as a reflection of societal attitudes, emotion, and values. With its universal appeal, pop music serves as a powerful medium that portrays well the influence of pop culture on the public and their collective sentiments. By delving into the lyrical content of popular songs, we can uncover valuable insights on the emotional landscapes and prevailing themes that resonate with the music community.

In this analysis, we will analyse lyrics of the top popular songs from 2019 to 2023. These songs are curated from Billboard annual top 100 singles. It is acknowledged that this selection may not capture the entire spectrum of musical preferences of all music listeners. Nonetheless, it still offers a representative impression of into the prevalent cultural mood. Through different techniques, including sentiment analysis, term frequency analysis, n-grams, and topic modelling, we seek to decipher the emotional experiences, societal concerns, and underlying narratives that define the common musical expression in this time period.

# Library

```{r}
#installing packages if needed
if (!require(tidyverse)) install.packages("tidyverse")
if (!require(rvest)) install.packages("rvest") #for scraping data from static web pages
if (!require(xml2)) install.packages("xml2") #for reading html files of the web pages
if (!require(cld3)) install.packages("cld3") #for detecting language
if (!require(tidytext)) install.packages("tidytext")
if (!require(hunspell)) install.packages("hunspell") #detect misspelling
if (!require(ggpubr)) install.packages("ggpubr") #combine ggplots into 1
if (!require(igraph)) install.packages("igraph") #prepare network graph
if (!require(ggraph)) install.packages("ggraph") #make network graph
if (!require(topicmodels)) install.packages("topicmodels") #topic modelling
```

```{r}
library(tidyverse) 
library(rvest) 
library(xml2) 
library(tidytext)
library(hunspell)
library(ggpubr)
library(igraph)
library(ggraph)
library(topicmodels)
```

Note: the package `geniusr` is an R package for using Genius API. The package is originally created by ewenme but there is an issue for function `get_lyrics`, which has been fixed by giovanni-cutri so we will use their version of `geniusr` package.

# Data Collection

The Billboard Year End Hot 100 singles compiles the top performing singles of the United States, considering both physical and digital sales. Although the charts are posted on the website of Billboard, in this analysis, we will get the information from Wikipedia since it has a more convenient format for scraping and it is open-source platform. To commence the data collection process, we can run a test scrape for the year 2023 and later scale to all the interested years.

**Important**: the lyrics collection process is a time-intensive task (around 30 minutes long). As such, the data set has already been provided and this step can be skipped directly to the Data Cleaning section.

## Test Scrape 2023

```{r}
#url of wikipedia page for top songs 2023
billboard100_2023 <- "https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_2023"

#check and clean scraped data and put into a readable format (dataframe)
read_html(billboard100_2023) %>% 
  xml_find_all("//table[contains(@class,'wikitable')]/tbody/tr[td]") %>% 
  xml_text() %>% 
  str_replace_all("\n", "") %>% 
  str_replace_all("\"", "%") %>% 
  dplyr::as_data_frame() %>% 
  separate_wider_delim("value","%", names = c("position", "song_name", "artists"))
```

The table containing the information that we need is a unique `<table>` element with the `class = 'wikitable'` and all the pages for other years have the same format so we can use the same syntax to scrape songs from all the years that we are interested in.

## Scrape All Songs

```{r}
#interested years
years <- c(2019:2023) 

#helper function to streamline the scraping process
get_top_songs <- function(year){
  url <- paste0("https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_", year)
  
  #save the scraped and cleaned data into a dataframe like previously
  df <- read_html(url) %>% 
  xml_find_all("//table[contains(@class,'wikitable')]/tbody/tr[td]") %>% 
  xml_text() %>% 
  str_replace_all("\n", "") %>% 
  str_replace_all("\"", "%") %>% 
  dplyr::as_data_frame() %>% 
  separate_wider_delim("value","%", names = c("position", "song_name", "artists"), too_many = "merge")
  
  df <- df %>% mutate("year" = year) #add a year column
  
  return(df)
}

#applying the helper function to a vector and returning a dataframe
all_top_songs <- map_dfr(years, get_top_songs)

all_top_songs
```

The final data frame has 500 rows, aligning with the 5 charts of the 5 years period (2019-2023). This indicates that the scraping process has run successfully and accurately. Our next objective is getting the lyrics of these songs in order to create a complete data frame. We will use Genius API to get the songs' information and lyrics. We will use the library `geniusr` which facilitates the use of Genius API.

**Important**: To reproduce this report using `geniusr` package, it is important to follow these steps from the guide of the package:

1.  [Create a Genius API client](https://genius.com/api-clients/new)
2.  Generate a client access token from the [API Clients Page](https://genius.com/api-clients)
3.  Calling `genius_token()` and enter your Genius Client Access Token

The full guide to the `geniusr` package is on this [GitHub page](https://github.com/ewenme/geniusr?tab=readme-ov-file)

Again, the data set is already provided and this can be skipped. To reproduce the data collection process, un-comment the code lines and run.

## Get Lyrics

```{r}
# if (!require(geniusr)) remotes::install_github("giovanni-cutri/geniusr") #api of genius website - contains lyrics and many information about songs and artists
# library(geniusr)

# #call and enter Client Access Token to authenticate to use Genius API
# genius_token()  
```

```{r}
# # helper function to get lyrics of a song
# just_lyrics <- function(artist, song){
#   #search for id of song based on song name and name of first artist
#   id <- search_song(paste(song, str_extract(artist, "\\w+( [A-Z]\\w+)?")))[1,1] %>% pull()
#   
#   #get lyrics based on id
#   get_lyrics_id(id) %>% 
#     .$line %>% 
#     paste(., collapse= " ")
# }
# 
# #add lyrics column to the data frame of songs from before
# all_songs_lyrics <- all_top_songs %>% 
#   mutate(
#     lyrics = mapply(just_lyrics, artists, song_name)
#   )
# 
# #save the complete data frame into a csv file for easy retrival for analysis later
# write_csv(all_songs_lyrics, "all_top_songs_lyrics.csv")
```

One way to get lyrics of a song using the `geniusr` package is to use the function `get_lyrics_id()` with a singular parameter `id` . This `id` can be retrieved by using the function `search_song` and the resulting table's first cell ([1,1]) is the id of the song. We built a helper function to facilitate the lyrics retrieval.

It took 31 minutes to scrape all the lyrics for the 500 songs so we will save the data into a csv file to avoid scraping every time we perform analysis. *This might make the reproduction of the analysis faulty to changes added after the publish date of the project.*

# Data Cleaning

```{r}
all_songs_lyrics <- read.csv("all_top_songs_lyrics.csv") %>% 
  drop_na()

wrong_lyrics <- c("Ritmo (Bad Boys for Life)", "My Ex's Best Friend", "Hrs and Hrs")

all_songs_lyrics <- all_songs_lyrics %>% 
  filter(!song_name %in% wrong_lyrics) 
```

The lyrics scraped were not perfect because some searches returned id of a remix of the song or a different language version of the song. Therefore, we have to identify and clean them. Upon examining the lyrics of these 500 songs, 3 songs with faulty lyrics were found and excluded from the list since, at this point, the limit of queries allowed from Genius API has already been reached.

```{r}
songs_en <- all_songs_lyrics %>% 
  mutate(
    lang = cld3::detect_language(lyrics)
  ) %>% 
  filter(lang == "en")
```

Out of all the songs, there are 25 songs in languages other than English. We either have to exclude them or translate them into English for the chosen analysis method of this analysis. This language detection was done using the `cld3` package - a neural network model for language identification. It was mentioned that the version used at the time of this project was still experimental so reproduction might produce different results. Another option to do this task could be using DeepL API. The package `deeplr` is available to facilitate the use of DeepL API and has functions for detecting and translating languages. However, DeepL free API is extremely limited and subscription is expensive. Therefore, for the scope of this project, we will use `cld3` package and exclude songs that are not in English.

# Split and Tokenize

```{r}
songs_en_st <- songs_en %>% 
  unnest_tokens(word, lyrics)
```

As is often when analyzing songs from pop culture, there are numerous potential issues for the analysis with the words used in these songs. In our case, there are many slang words that are not recorded in dictionaries as well as variations in pronunciation used for rhyming or stylistic purposes. Some examples of these words are "nothing" becoming "nothin", "fighting" becoming "fightin", and so on.

We will try to clean these as much as possible but it is important to acknowledge that the task can be quite complex and messy. There are packages that can help correcting the misspelling (e.g., `textclean`, `hunspell`) but these are usually not accurate for slang and words specific to pop culture. Stemming and lemmatization techniques can help, but they also run the risk of inadvertently removing valuable information or incorrectly stemming or lemmatizing words (for example, some packages reduce "is" to "i" or give errors to slang and words related to pop or internet culture).

```{r}
misspelling_dict <- songs_en_st %>% 
  select(word) %>% 
  distinct() %>% 
  mutate(misspelling = hunspell_check(word)) %>% 
  filter(misspelling == FALSE) %>% 
  #important misspelling are verb-ing words so we will correct by adding g at the end of word
  mutate(ing_word = str_detect(word, pattern = "\\w+in$")) %>% 
  filter(ing_word == TRUE) %>% 
  mutate(correction = paste0(word, "g")) %>% 
  #double check again to include only words correctly corrected
  mutate(misspelling_2 = hunspell_check(correction)) %>% 
  filter(misspelling_2) %>% 
  select(word, correction)
misspelling_dict
```

To address the issue of misspelled words within the song lyrics data set, we will use the `hunspell` package to identify these spelling errors. We can observe that most of the identified misspelled words are either verbs ending in "ing" (present participle or gerund) and names or words from other languages or slang. Since names and pop culture words contribute meaning to the song and are not entirely affected by the analysis, we will only correct the verb-ing words so they can be identified by the lexicons used in the subsequent section. To achieve this, we initially detect misspelled words ending with "in" and subsequently append "g" to the of the word. They are checked again by the `hunspell_check` to filter out other words that also end with "in" but are not verb-ings.

```{r}
songs_cleaned <- songs_en_st %>% 
  left_join(misspelling_dict, by = join_by(word)) %>% 
  mutate(correct_word = ifelse(is.na(correction), word, correction)) %>% 
  select(-word, -correction) %>% 
  rename(word = correct_word)

songs_cleaned
```

We consolidate the final, cleaned version of the dataset by joining the misspelling dictionary data frame with the original data frame. We then create a new column wherein misspelled words are replaced with the corrected form, while original words remain unchanged if not found in the dictionary.

# Filter Stop Words

```{r}
songs_en_filtered <- songs_cleaned %>% 
  anti_join(stop_words)

songs_en_filtered
```

# Lexicon-based Sentiment Analysis

In the following section, we will explore the sentimental themes prevalent in the popular songs spanning from 2019 to 2023. Our aim is to uncover insights into the sentiments of music listeners and whether they relate or reflect the events that unfolded during these years.

Numerous adverse events happened during this period, including the COVID-19 pandemic and ongoing conflicts between countries. This leads us to anticipate an increase in songs reflecting themes of loneliness or sadness. However, there is also potential for an emergence of songs with themes of courage and happiness. It is plausible that listeners might turn into uplifting music as a means of coping and finding solace during the tough times.

```{r}
#create data set with sentiment values using bing
sa_df_bing <- songs_en_filtered %>% 
  inner_join(get_sentiments("bing")) %>% 
  group_by(year, song_name, artists) %>% 
  count(sentiment) %>% 
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% 
  mutate(sentiment = positive - negative) %>% 
  mutate(sentiment_label = ifelse(sentiment == 0, "neutral", ifelse(sentiment > 0, "positive", "negative")))

sa_df_bing$sentiment %>% summary()
```

```{r}
#create data set with sentiment values using afinn
sa_df_afinn <- songs_en_filtered %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(year, song_name, artists) %>% 
  summarise(sentiment = sum(value)) %>% 
  mutate(sentiment_label = ifelse(sentiment == 0, "neutral", ifelse(sentiment > 0, "positive", "negative")))

sa_df_afinn$sentiment %>% summary()
```

We are using 2 lexicons "bing" and "afinn" to measure the sentiments of words of the songs. With "bing", a song is classified as "positive" if the net value of positive words subtracting negative words is greater than 0 (positive - negative \> 0), "negative" if it is below 0 (positive - negative \< 0), and "neutral" otherwise (positive - negative = 0). With "afinn", this sentiment label is categorized by the sum sentimental values of words with the same criteria for "bing".

A brief descriptive analysis on the sentiment attribute shows that more than half of the songs carry negative connotation in their lyrics with means of -8.3 and -16.8 and medians of -6 and -5 for "bing" and "afinn" repsectively. It also shows that the negative notation has a peaked value almost double the positive (-83 compared to 42 for "bing" and -325 compared to 163 for "afinn"). This means that the song with the highest negative connotation has almost double the amount of negative words or negativity than the top positive song. We can see this more clearly with the box-plots below.

```{r}
#box-plot for sentiment column
ggarrange(
  ggplot(sa_df_bing) + geom_boxplot(aes(y = sentiment)),
  ggplot(sa_df_afinn) + geom_boxplot(aes(y = sentiment)),
  labels = c("bing", "afinn")
)
```

## Song sentiment over the years

```{r}
#combine afinn and bing data set to compare song sentiment over the years
oty <- bind_rows(
  sa_df_afinn %>% mutate(method = "afinn"),
  sa_df_bing %>% select(-negative, -positive) %>% mutate(method = "bing")
)

#visualize
oty %>% 
  group_by(method, year, sentiment_label) %>% 
  count() %>% 
  ggplot() +
  ggalt::geom_xspline(aes(year, n, color = sentiment_label)) + #geom_xspline for smooth line
  xlab("year") +
  ylab("number of songs") +
  facet_wrap(~method, ncol = 1, scales = "free_y")
```

Although the 2 lexicons yield divergent results regarding the overall sentiment of songs, they both appear to concur on the fluctuation of negative and positive songs post-2020. In 2021, the number of positive songs rose while the number of negative songs plummeted. This trend, however, reserved from 2021 to 2023, with negative songs starting to ascend and the positive songs dwindling. From 2019 to 2020, it seems that using "bing" gives us a fall in negative songs and an increase in positive songs but with "afinn" this pattern is inverted. Despite the difference in trend, the increase or decrease are relatively minor in both graphs. Furthermore, both lexicons also agree on the minimal number of neutral songs, which aligns with the nature music, as songs tend to express a lot of emotions.

It is challenging to determine whether our initial or latter hypothesis about the music listening trend was correct since the 2 lexicons produced disparate results for the period 2019 to 2020. Although number of negative songs outweighed the number of positive songs, it remains uncertain whether this represents a perpetual trend within pop culture or a singular phenomena specific to this period. However, the trend after 2020 offers greater clarity. The COVID-19 pandemic started around December 2019 and began to spread worldwide in early 2020. Following this pandemic was a series of lock down in populated cities and was lifted after mid 2021 for the majority of places. The end of the quarantine allowed reunion between loved ones and represented a signal of the waned sign of COVID-19. Thus, this gave rise to celebration and positive sentiments, which seem to be reflected accordingly in the graphs. The graphs then show a surge of popularity of negative songs in 2022 and 2023. This could reflect the sentiment against the series of misfortune events that happened such as the conflict of Russia and Ukraine, soaring inflation rate, and various droughts and floods in many regions, etc.

## Most common positive and negative words

Previously, we learned that some songs could exhibit extreme negativity while very positive songs do not contain as abundant positive words. Additionally, there seems to be a trend of pop culture where negative songs dominate in number in the charts in all years. We will explore deeper into the vocabulary used in the songs to understand better the underlying reasons of these phenomena.

```{r}
#count words to find top used words
common_words_bing <- songs_en_filtered %>%
  inner_join(get_sentiments("bing")) %>% 
  count(word, sentiment, sort = TRUE)

#visualize
ggplot(common_words_bing %>% filter(n > 50)) +
  geom_col(aes(reorder(word,n), n, fill = sentiment)) +
  coord_flip() +
  facet_wrap(~sentiment, scales = "free_y") +
  xlab("word") +
  ylab("count")
```

It seems that positive words concentrates on the word "love" whereas negative words spread out on various terms. The majority of the negative word use is curse words, however, it is worth noting that some of these words can carry different sentimental notation other than negative depending on the context in which they are used. For example, "shit" and "damn" could be an affirmation of positive feeling when paired with words like "good". We will subsequently analyze this phenomenon on a deeper level in another section.

Among the negative words identified, some interesting negative words are "miss", "lost", "lonely", "die". Although they are common terminologies that are used in various situations, they are highly related to the mishaps of the major events that happened during this time period. For instance, the prolonged quarantines may have contributed to the popularity of the words "miss" and "lonely" while the toll of COVID-19 and the wars might have accounted for the hightened use of "lost" and "die".

Conversely, the positive word chart features words that are quite commonplace and general. It was initially anticipated with more words that indicate hope or courage but they did not show up here.

```{r}
#count words to find top used words
common_words_afinn <- songs_en_filtered %>%
  inner_join(get_sentiments("afinn")) %>% 
  count(word, value, sort = TRUE) %>% 
  mutate(sentiment = case_when(
    value < 0 ~ "negative",
    value > 0 ~ "positive",
    TRUE ~ "neutral"
  ))

#visualize
ggplot(common_words_afinn %>% filter(n > 50)) +
  geom_col(aes(reorder(word,n), n, fill = sentiment)) +
  coord_flip() +
  facet_wrap(~sentiment, scales = "free_y") +
  xlab("word") +
  ylab("frequency")
```

With "afinn" lexicon, we get a similar result. Most popular negative words are curse words while popular positive words concentrate on "love" and "yeah". However, words like "hope" and "care" do appear to have some importance. "God" is also an interesting word that could indicate how the situations might have brought out people's need for faith.

We will next look at the common words by year to have a clearer picture of each year.

```{r}
#count words by year
common_words_by_year_bing <- songs_en_filtered %>%
  inner_join(get_sentiments("bing")) %>% 
  count(year, word, sentiment, sort = TRUE)

#visualize
ggplot(common_words_by_year_bing %>% filter(n> 30)) +
  geom_col(aes(reorder(word,n), n, fill = sentiment)) +
  coord_flip() +
  facet_wrap(~year, scales = "free_y") +
  xlab("word") +
  ylab("frequency")
```

Upon examining the data year by year, it seems that there is evidence supporting our earlier hypothesis. In 2020 and 2021, the words "lonely" and "miss" rank in the top common words used in the popular songs. This could suggest that the pandemic and the lock down produced some nostalgic effect for people. Additionally, some words like "love", "shit", "bitch", "fuck" seem to be time-less, in that they consistently appear in all years.

It is also interesting that in 2019 and 2020, usage of sentimental words seemed to spread out more while from 2021 to 2023, and especially in 2022, certain words are overly repeated. Perhaps, 2022 was not a very creative year in song writing. Finally, although using "afinn" gives longer list of top words, their pattern are similar to using "bing". The results of using lexicon affin are displayed below.

```{r}
#count word by years
common_words_by_year_afinn <- songs_en_filtered %>%
  inner_join(get_sentiments("afinn")) %>% 
  count(year, word, value, sort = TRUE) %>% 
  mutate(sentiment = case_when(
    value < 0 ~ "negative",
    value > 0 ~ "positive",
    TRUE ~ "neutral"
  ))

#visualize
ggplot(common_words_by_year_afinn %>% filter(n> 30)) +
  geom_col(aes(reorder(word,n), n, fill = sentiment)) +
  coord_flip() +
  facet_wrap(~year, scales = "free_y") +
  xlab("word") +
  ylab("frequency")
```

## Top Songs

```{r}
#assign sentiments for only songs at 1st position of the chart
top_songs_bing <- songs_en_filtered %>%
  filter(position == 1) %>% 
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) 
  
#visualize
ggplot(top_songs_bing) +
  geom_col(aes(reorder(word,n), n, fill = sentiment)) +
  coord_flip() +
  facet_wrap(~sentiment, scales = "free_y") +
  xlab("word") +
  ylab("frequency")
```

Having previously examined the overall sentiments expressed in all songs, it is worth exploring whether the top songs convey distinct emotions that set them apart. To investigate this, we will narrow down our dataset to include only songs that held the first position in the charts.

For the top songs, there are positive words in common to all songs such as "love", "loving", "trust" and "woo". However, we also see some more specific and more intensely positive words such as "happier", "perfect", "perfectly", and "glitter". On the negative word graph, they also use profanity such as "shit" and "hell". "shimmer" seems to be considered negative in bing lexicon but the word's definition does not exactly coincide so we will not consider it. Notably, however, the negative words are also more nuanced and profound with words such as "drowning" and "cold".

```{r}
#assign sentiments for only songs at 1st position of the chart
top_songs_afinn <- songs_en_filtered %>%
  filter(position == 1) %>% 
  inner_join(get_sentiments("afinn")) %>% 
  count(word, value, sort = TRUE) %>% 
  mutate(sentiment = case_when(
    value < 0 ~ "negative",
    value > 0 ~ "positive",
    TRUE ~ "neutral"
  ))

#visualize
ggplot(top_songs_afinn) +
  geom_col(aes(reorder(word,n), n, fill = sentiment)) +
  coord_flip() +
  facet_wrap(~sentiment, scales = "free_y") +
  xlab("word") +
  ylab("frequency")
```

Using afinn lexicon, we further see that the negative words used in the top songs carry more criticism with words like "faking" or "fake". We also see very emotional theme with "empty", "lost", "broken", and "cheated".

For now, it is still unclear what topics that the songs sing about. We have only seen that these songs seem more emotional and use less profanity to express the bad feelings while using more specific words to describe good feelings. We will later on examine the context of songs better with term frequency and n-gram analysis.

## Top Artists

We have observed that some artists demonstrate a tendency for either very negative or positive sentiments in their song. We have also seen before that negative songs seem to dominate in popularity in the pop charts. This raises a question of whehter this suggest that an artist might have a better chance at getting more songs in the top positions by choosing more negative songs. We can investigate this hypothesis by examining the top artists that had the most songs placed in these top 100 boards, and check their ratio of positive versus negative songs.

```{r}
#make a data frame of top 10 artists (with most songs in the charts) of the period
artists_sa <- bind_rows(
  sa_df_afinn %>% group_by(artists) %>% count(label = sentiment_label) %>% mutate(method = "afinn"),
  sa_df_bing %>% group_by(artists) %>% count(label = sentiment_label) %>% mutate(method = "bing")
) %>%
  group_by(method, artists) %>% 
  mutate(total_songs = sum(n)) %>% 
  group_by(method) %>% 
  slice_max(n=20, order_by = total_songs, with_ties = TRUE) 

#visualize  
artists_sa %>% ggplot() +
  geom_col(aes(reorder(artists, total_songs), n, fill = label)) +
  coord_flip() +
  facet_wrap(~method, scales = "free_y") +
  xlab("Top artists") +
  ylab("number of songs")
```

Using "afinn" and "bing" gives us different results. However, the common pattern is clear. Most of these top artists had a predilection for negative songs. "Luke Combs", "Ariana Grande", and "Post Malone" are the few that made their fame by singing more positive songs, according to "afinn". However, the messages of their songs might not so much be negative in reality if taken into account the context of the whole song. The results here only indicate that the words employed in those songs are defined to carry negative notions by the lexicons. An educated guess could be that their lyrics contain a lot of profanity, which is very much normalized in pop culture. We will next examine on a deeper level of the words used and related word statistics to detect important words.

# Term Frequency Analysis

Based on our sentiment analysis, it is evident that the pop culture tends to gravitate towards the use of negative words, particularly profanity. We also looked at some top sentiment words of songs to understand what emotional message that the songs tried to convey. Finally, we discovered that the majority of the top artists in the music charts achieved their success by singing songs with more negative themes. In this section, we will dive deeper into the content of the songs to discover what the common objects of attention in the pop music community are.

## Word Count

```{r}
#create a data frame with count of words and total amount of words of the song
song_words <- songs_cleaned %>% 
  count(position, year, song_name, word, sort = TRUE) %>% 
  group_by(year, song_name) %>% 
  mutate(total_words = sum(n),
         term_freq = n/total_words,
         position_level = ifelse(position <= 10, "Top 10", "Top 100")) %>% 
  ungroup()

#word count distribution
ggplot(song_words) +
  geom_histogram(aes(total_words, fill = position_level)) +
  xlab("Total word count per song") +
  ylab("Frequency")
```

Most songs tend to be around 3 to 4 minutes in length. This is due to how vinyls were made in the 1800s and 1900s, which limited the the length of music that can be written onto them (from the article of [Vox](https://www.vox.com/2014/8/18/6003271/why-are-songs-3-minutes-long)). The article also explained that although the evolution of technology allowed songs to recorded for a longer period of time, the radio and digital media industry influenced music to stay short in order to be able to be enter the mainstream.

Undoubtedly, with limited amount of time, the length of songs' lyrics also stay within a certain range. We can see this from the graph above. Most songs tend to have around 300 to 600 words. Top 10 songs are also mostly in this range. Thus, we can hypothesize that lengthy and wordy songs might have less chances of making it to the top 10.

```{r}
#compare average word counts of top 10 vs the rest of top 100
ggplot(song_words) +
  stat_summary(aes(year, total_words),
               fun.y = "mean",
               geom = "bar") +
  facet_wrap(~position_level)
```

This phenomenon does not seem to change through time. Songs seem to stay consistent in lyrics length in all the years and top 10 songs seem to be slightly shorter than the top 100.

## Term Significance

```{r}
#visualize term frequency distribution
ggplot(song_words, aes(term_freq)) +
  geom_histogram() +
  xlim(0, 0.15)
```

Similar to novels, songs seem to share a long tail distribution in word frequency. Some words are more common and appear more frequently and there are words that make the songs more unique. We will explore them further on the analysis.

```{r}
#visualize term frequency distribution for each year
ggplot(song_words, aes(term_freq)) +
  geom_histogram(show.legend = FALSE) +
  xlim(0, 0.05) + 
  facet_wrap(~year, scales = "free_y")
```

We can also ascertain that this phenomenon is steady throughout the years by looking at the graph above of the word distribution year by year. It is evident that words have higher frequency compared to the rest. By looking at them, we can better understand the important words of a song and consequently what the song is about. We will next analyze the term frequency for each year to identify words that characterize them.

```{r}
#filter top 10 words with highest term frequency for each year
top_term <- song_words %>% 
  group_by(year) %>% 
  slice_max(term_freq, n=10) 

#visualize
ggplot(top_term) +
  geom_col(aes(term_freq, reorder(word, term_freq))) + 
  ylab("word") +
  xlab("frequency") +
  facet_wrap(~year, scales = "free_y")
```

It seems that some significant words are vocal sounds (e.g., "ooh", "la", "bam", etc.). Although they contribute to the songs vocally, they do not carry much semantic meaning and therefore we will filter them out to get a better picture of the songs' messages.

```{r}
#make a list of vocal sounds and sounds that do not contribute any semantic meaning
vocal_sounds <- c("ah", "ody", "boaw", "ooh", "oh", "bam", "da", "na", "woah", "yaka", "la", "doo", "ding", "dong", "buh", "blrrrd", "o","tu", "bo", "teh", "yuh", "lo", "ough", "eno", "sha", "taki", "que", "grrah", "ma", "dum", "onely", "nah", "ee", "p", "ba", "ahh", "mhm", "ayy", "uh", "huh", "woo", "mmm", "mm", "bop", "yeah")

#filter top 10 words with highest term frequency for each year
top_term <- song_words %>%
  filter(!word %in% vocal_sounds) %>% 
  group_by(year) %>% 
  slice_max(term_freq, n=10) 

#visualize  
ggplot(top_term) +
  geom_col(aes(term_freq, reorder(word, term_freq))) + 
  ylab("word") +
  xlab("frequency") +
  facet_wrap(~year, scales = "free_y")
```

After eliminating the vocal sounds, we can see that there are some common themes that characterize the top songs for each year. "i" and "you" appear in all years, suggesting that the top songs tend to have a first person perspective. This could make the song more personal and better connect with the listeners. The context of the songs, however, remain hazy and not distinctive enough to draw conclusions on the relevant topics of the years. We will now compute the inverse document frequency to address this issue.

```{r}
#some songs are in the top charts for several years and tf-idf do not work with group() so we will create a function to do this per year
map_tf_idf <- function(y) {
  df <- song_words %>% 
    filter(year == y) %>% 
    filter(!word %in% vocal_sounds) %>%
    bind_tf_idf(word, song_name, n)
}

#binding all the years to create a single dataframe with all the years
songs_tf_idf <- map_dfr(c(2019:2023), map_tf_idf)
songs_tf_idf

#visualising top relevant words of each year
songs_tf_idf %>% 
  group_by(year) %>%
  slice_max(tf_idf, n = 15) %>%
  ungroup() %>% 
  ggplot(aes(tf_idf, reorder(word, tf_idf))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~year, scale = "free") +
  labs(x = "tf-idf", y = NULL)
```

Some songs are present in the top 100 charts in multiple years, which will create issue when using the function `bind_tf_idf()` (giving negative idf values). Therefore, we will need to group them by year. However, the function `bind_tf_idf()` ignores groups so we have to do it separately. In the code, a helper function was created which takes our original data frame of words with count and filters it by an input year and the meaningless sounds, then finally creates new "tf", "idf", and "tf_idf" columns with `bind_tf_idf()`. The output of this function is a data frame of songs and their filtered words for one year. We then use the function `map_dfr()` to apply the function on an array of years to ultimately obtain a data frame of songs with "tf", "idf", and "tf_idf" values that are grouped by year.

We observe that although some words stand out more prominently than other in each year, we can still discern some recurring themes that persist across all years. For example, there is a inclination towards incorporating a woman figure in the songs with words such as "girlfriend", "roxanne", "woman", and "she". Words about intoxication are also very relevant in the recent years with the appearance of "tripping", " margarita", and " wasted". Romance is also one theme that is distinguished from the appearance of words such as "girlfriend", "heartless", and "heartbreak". Words like "hopes", "lord", "amen", "holy", and "karma" also signify the importance of faith or spiritual belief.

These themes, while prevalent in recent years, have persisted as central motifs throughout the history of music and other literature. They tap into emotions that resonate deeply with people and therefore do not surprisingly come as important topics.

It is also important to point out that from 2021 to 2023, Christmas songs seem to make a come back to the top as words like "christmas", "jolly", "holly", "jingle" and "bell". Christmas is centered around reunions with family and friends, something of which people were deprived during the series of lock down due to the pandemic. Thus, it is possible as the pandemic subsided, people are spirited to embrace the holidays once again as they could then enjoy without the constraints of restrictions.

## Top songs

```{r}
#visualize top words with highest tf-idf of top 1 song of each year
songs_tf_idf %>% 
  filter(position == 1) %>% 
  group_by(year) %>%
  slice_max(tf_idf, n = 15) %>%
  ungroup() %>% 
  ggplot(aes(tf_idf, reorder(word, tf_idf))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~year, scale = "free") +
  labs(x = "tf-idf", y = NULL)
```

From the sentiment analysis, we have learned that the top songs stand out by employing more nuanced and emotional words. We can learn more about their focal points by examining the top tf-idf values of each song.

The top song in 2019 seems to sing about riding horses on an old town road. This is probably metaphorical, which we can try to decipher later by looking at pairs and groups of words. The song also contains words like "nothing" and "nobody" so there is a possibility that the song means to sing about the state of being alone or different from the rest. Connecting with the previous context on an old town road, perhaps, the singer implies a narrative of transformation from their origin.

Next, in 2020, it seems to be more of a sad song through words like "blinded", "empty", and "drowning". Probable context for "blinded" is "blinded" by the "city's" "lights". Words such as "empty", "drowning", "sleep", "trust" and "touch" could imply a romantic or sensual affair that turned stale.

The top song in 2021 seems, however, to be a more energetic, fun, and positive song with words such as "levitating", "dance", and "blast". Overall, the song seems to simply convey a message about enjoying the "night" "tonight" with "moonlight" and the song connects directly with the listeners by the use of "you're" and invites them on the journey with words like "ride", "fly" and "away".

2022's top song seems to have a summer vibe with top words being "heat", "waves", "june". It is not, however, about enjoying the summer because the words are quite intense and bear some discomforting feelings. The song also sings about "middle" and "nights" where the singer might "sometimes" "think" "about" something and have a "vision".

Finally, 2023 was topped by a seemingly sad song about romance. There is a clear narrative of at least 2 people involved as the song uses a lot of "we" and "our". It also potentially feature dialogues with words like "telling" and "said". Nostalgic collections are also a topic of the song with words like "remember" which seems to be invoked through "liquor".

# N-grams

We have explored the sentimental and possible themes of the top songs from 2019 to 2023 but the story they tell still remains ambiguous. Pop songs often weave in metaphors and employ words in nuanced ways that cannot be simply interpreted through looking at individual words. In this section, we will look at words of the lyrics in pairs and groups and try to connect them in order to get a fuller picture of the songs. The approach will be looking at pairs of words and then groups of 3 words so we can understand better what the meaning embedded within the songs.

## Bigram

### Preparing data

```{r}
#create a bigram data frame
song_bigram <- songs_cleaned %>%
  select(-lang) %>% 
  #nest back clean dataframe to avoid correcting the spelling again
  nest(lyrics = word) %>% 
  #nest gives a list of list so we have to unlist them
  mutate(lyrics = map(lyrics, unlist),
         lyrics = unlist(lapply(lyrics, paste, collapse = " "))) %>% 
  #unnesting to bigrams 
  unnest_tokens(bigram, lyrics, token = "ngrams", n = 2)

song_bigram %>% 
  count(bigram, sort = TRUE)
```

First to convert words into pairs, we will stitch back the cleaned data frame with individuals words into a data frame with each row representing each column. This is because during the cleaning process, we corrected the spelling of many words and then tokenized the data set. If we were to use the original, uncleaned data set we would have to go through the cleaning process again. Therefore, here the cleaned data frame is stitched back and unraveled into pairs of words, or bigrams.

Looking at the counts, we can see that there are many bigrams that are made up of stop words and vocal sounds that do not contribute much meaning to the songs. Therefore, we will filter them out.

```{r}
#separate the bigrams in order to filter
bigram_seperated <- song_bigram %>% 
  separate(bigram, c("word1", "word2"), sep = " ")

#filter rows that has stop words or vocal sounds
bigram_filtered <- bigram_seperated %>% 
  #filter stop words
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word) %>% 
  #filter vocal sounds
  filter(!word1 %in% vocal_sounds) %>% 
  filter(!word2 %in% vocal_sounds)

#stitch back the bigrams
bigram_united <- bigram_filtered %>% 
  unite(bigram, word1, word2, sep = " ")

bigram_united
```

Above, we first separate the bigrams into 2 columns of individual words. We then filtered for each columns of rows that contained the stop words and vocal sounds from the list we created before. We then united the words together to have a final data frame similar to the original but with less meaning less bigrams. Now, we can explore better the context of the songs.

```{r}
#visualize top bigrams with highest frequency
bigram_united %>% 
  group_by(year) %>% 
  count(bigram, sort = T) %>% 
  slice_max(n, n = 10) %>%
  ungroup() %>% 
  ggplot(aes(n, reorder(bigram, n))) +
  geom_col() +
  facet_wrap(~year, scales = "free_y") +
  xlab("frequency") +
  ylab("word")
```

It seems that across all years, slang and profanity are frequently present. This sheds light on the reason why sentiment analysis yielded abundant negativity in the songs. However, in reality and current culture, this might not be the case. For example, the word "bitch" carries a negative connotation but when paired with "bad", it might not necessarily mean "bad" but rather have a more positive connotation culturally speaking. Overall, there are still many common pairs that do not capture the full meaning of the songs so we will use tf-idf in order to take them out and shift the focus to more relevant words.

### TF-IDF

```{r}
#create data frame of bigram with tf-idf values
bigram_tf_idf <- bigram_united %>%
  count(year, bigram) %>%
  bind_tf_idf(bigram, year, n) %>%
  arrange(desc(tf_idf))

#visualize for each year
bigram_tf_idf %>% 
  group_by(year) %>% 
  slice_max(tf_idf, n = 10) %>% 
  ggplot() +
  geom_col(aes(tf_idf, reorder(bigram, tf_idf))) +
  facet_wrap(~year, scale = "free_y")
```

Looking at bigram frequency, we can see some themes similar to the term frequency analysis starting to emerge. Bigrams like "girlfriend girlfriend", " girl summer", "roxanne roxanne", "woman woman", and "broadway girls" indicate that female is a relevant topic for the recent years. Spiritual or religious matter is also important as word pairs like "god's country", " talking god", and " god makes" show up in the charts. It is interesting that in 2021, there are 2 bigrams related to god. Like previously mentioned, the world had just witnessed the havoc of the pandemic, thus, it could be a reason why people are listening to songs related to their faith. We can also see that in 2019, before the pandemic, songs stand out with words talking more about enjoying life and having fun from bigrams such as "whiskey glasses", "girl summer", and "taste tequila". In 2020, there are not many of similar words but rather a new emergence of more sentimental words such as "memories bring" and "feeling feeling". In 2021 and 2022, however, they come back with words like "shaking ass", "knees shaking", and "sigue bailando" (keep dancing).

In order to understand better the relationship and connections of these words, we will map them out into a network and identify clusters that characterize the recent years in music lyrics.

### Graph

```{r}
set.seed(507)

bigram_count <- bigram_filtered %>%
  count(word1, word2 , sort = TRUE)

#prepare graph  
bigram_for_graph <- bigram_count %>%
    filter(n > 8) %>%
    graph_from_data_frame()

#visualize graph
ggraph(bigram_for_graph, layout = "fr") +
    geom_edge_link(aes(edge_alpha = n, edge_width = "1px"), show.legend = FALSE) +
    geom_node_point() +
    geom_node_text(aes(label = name), vjust = 1.5, hjust = 0)
```

From mapping out the connections and relationships of words, we can observe a few clusters that offer insights into the prevailing topics in the recent year.

First, there is a notable cluster around the word "wanna", suggesting a common tendency to sing about desires. The word "wanna" also has the strongest connection with the word "feel", indicating that desire for sentiment is possibly most frequent. There is also a cluster around the word "about", the connections are with "thinking", "talking", and "worried". Although they are words that frequently pair with the preposition "about", it is interesting to point out that "thinking" has the highest connection with "about". This closely relates to the theme of desire and contemplation.

There is a dense cluster around the words "bad" and "bitch". Their neighbors are "bitches", "guy", "habits", "lil", and "ass". We discussed before that there is a trending attitude in the pop culture of a "bad bitch" persona. This cluster seems to confirm this phenomenon with other similar pairs of "bad" and "bitches", "real" and "ass" and "bitch".

We also see a smaller cluster around "love". It is, however, surrounded by more negative words namely "ruin", "savage", and "lies". There is also another small cluster related to this topic formed by the words "heart", "broken", and "cold". We already learned that romance or love is a common topic. Here, we get a more specific picture of how love is sung about, which is more on the sorrow side. It seems that in the recent years, sad love songs are more dominant than happy ones.

The cluster around "girl" also has some interesting connection. "Hot girl summer" was a trending term on social media and it is also present here. The song(s) containing these words perhaps helped popularized it. "baby" is also a prominent word pair for "girl", which is normal as it is a quite common way that some men address at girls. "freaky", however, also seems a strong connection with "girl". Although this might not be direct sexualization but it could be so implicitly. This is a topic that has a long run in history and it seems to persist in the modern day.

Finally, Christmas seems to be many's favorite as we can see some clusters of the relevant words such as "holly", "jolly", "christmas", and "tree", and "jingle", "bell", and "rock". We have noted this before in the tf-idf analysis and saw that it seems to have surged in popularity after 2022.

## Trigram

```{r}
song_trigram <- songs_cleaned %>%
  select(-lang) %>% 
  #nest back clean dataframe to avoid correcting the spelling again
  nest(lyrics = word) %>% 
  #nest gives a list of list so we have to unlist them
  mutate(lyrics = map(lyrics, unlist),
         lyrics = unlist(lapply(lyrics, paste, collapse = " "))) %>% 
  #unnesting to trigrams 
  unnest_tokens(trigram, lyrics, token = "ngrams", n = 3)

song_trigram %>% 
  count(trigram, sort = TRUE)
```

Bigram has given us a better context about the songs and shown the story of each year as well as all the years. We can extend the analysis by looking at groups of 3 words, or trigrams, to further understand the context and identify some popular terms being used. The preparation is similar to making bigrams. The cleaned data frame of songs with individual words are stitched back together then re-unraveled into trigrams. From the trigram count, we still need to clean out the vocal sounds to obtain word groups that have meaning.

```{r}
trigram_seperated <- song_trigram %>% 
  separate(trigram, c("word1", "word2", "word3"), sep = " ")

trigram_filtered <- trigram_seperated %>% 
  #filter stop words
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word) %>% 
  filter(!word3 %in% stop_words$word) %>% 
  #filter vocal sounds
  filter(!word1 %in% vocal_sounds) %>% 
  filter(!word2 %in% vocal_sounds) %>% 
  filter(!word3 %in% vocal_sounds) %>% 
  filter(word1!=word2 & word2!=word3 & word1!=word3)

trigram_united <- trigram_filtered %>% 
  unite(trigram, word1, word2, word3, sep = " ")

trigram_united %>% 
  group_by(year) %>% 
  count(trigram, sort = T) %>% 
  slice_max(n, n = 10) %>%
  ungroup() %>% 
  ggplot(aes(n, reorder(trigram, n))) +
  geom_col() +
  facet_wrap(~year, scales = "free_y") +
  xlab("frequency") +
  ylab("word")
```

After filtering out stop words and vocal sounds, we still got many groups of repeating singular word (e.g., "woman woman woman") or repeating pairs (e.g., "jingle bell jingle" from "jingle bell jingle bell"). These groups are extraneous since we examined them in term frequency analysis and bigram analysis. Therefore, we will exclude them and look at groups of different words that might be more interesting for the analysis. The exclusion was done by filtering out rows that have word 1 equal to word 2, word 2 equal to word 3, and word 1 equal to word 3.

In 2019, it seems that some songs with spanish lyrics gained popularity as we see groups of Spanish words. We can also see that the term "hot girl summer" probably started to rise rapidly in popularity from this year. This term seems to be followed up by another song using the term "hot girl bummer" in response in 2020. It also seems that "god" was not exactly used in a context of faith but something else related to drinking as we see the terms "beer talking god", "drinking beer talking", and "talking god amen". Finally, we again see the Christmas terms "holly jolly christmas" rising in 2022 and 2023.

```{r}
trigram_tf_idf <- trigram_united %>%
  count(year, trigram) %>%
  bind_tf_idf(trigram, year, n) %>%
  arrange(desc(tf_idf))

trigram_tf_idf %>% 
  group_by(year) %>% 
  slice_max(tf_idf, n = 10) %>% 
  ggplot() +
  geom_col(aes(tf_idf, reorder(trigram, tf_idf))) +
  facet_wrap(~year, scale = "free_y")
```

Using tf-idf, we obtain similar results with just the term frequency. These word groups seem to be relevant and distinct for each year.

## Top songs

```{r}
#visualize top bigrams with highest tf-idf for top song of each year
bigram_united %>% 
  filter(position == 1) %>% 
  count(year, bigram) %>%
  bind_tf_idf(bigram, year, n) %>%
  arrange(desc(tf_idf)) %>% 
  ggplot() +
  geom_col(aes(tf_idf, reorder(bigram, tf_idf))) +
  facet_wrap(~year, scale = "free_y")
```

Looking at individual words have already given us a big context of the top most popular songs of 2019 to 2023. We can drill deeper into in what context are the words used so we can check whether the interpretation we made previously was adequate.

It seems that the context of the word use was interpreted correctly. The song in 2019 main line seems to be riding horse on an old town road. The other pairs do not exactly give us more information about the idea of the songs but do show us there is a theme around old town and cowboy in the song. The bigrams of the top song in 2020 confirms that there is a sensual notation with pairs such as "touch baby", "overdrive baby", and "sin city's". 2021's song of the year is affirmatively energetic and uplifting. There are a lot of sparks with pairs like "life glitter" , "sky glitter", and "eyes shining". Meanwhile, 2022's song conveys a suffocating feeling with "heat waves", "late nights", "gonna lose", and "fake water". Lastly, the top song of 2023 has some connected bigrams such as "baby something's" and "something's telling", and "talking bout" and "bout life". The other pairs seem to confirm that the song meant to sing to a lover about life in a night setting which was induced by alcohol.

# Topic Modelling

## Topic detection

Previously, through sentiment analysis, term frequency analysis, and n-gram analysis, we have detected some common themes that top pop songs from 2019 to 2023 sing about. These include love, faith, women, Christmas, dancing, desires and more. In this section, we will utilize an unsupervised machine learning technique to automatically identify the major topics sung about in the songs. This technique is done using the LDA (Latent Dirichlet Allocation) algorithm.

```{r}
#create a dtm object to use lda algorithm
songs_dtm <- songs_en_filtered %>% 
  select(-lang) %>% 
  filter(!word %in% vocal_sounds) %>% 
  #nest back clean dataframe to avoid correcting the spelling again
  nest(lyrics = word) %>% 
  #nest gives a list of list so we have to unlist them
  mutate(lyrics = map(lyrics, unlist),
         lyrics = unlist(lapply(lyrics, paste, collapse = " "))) %>% 
  distinct(song_name, .keep_all = TRUE) %>% 
  unnest_tokens(word, lyrics) %>% 
  count(word, song_name, sort = TRUE) %>% 
  cast_dtm(song_name, word, n)

songs_dtm
```

In order to use this algorithm, we first need to convert the data frame into DTM (document term matrix) format. We will use the data frame that has stop words filtered out and we will eliminate the vocal sounds in sequence as these words are present in most songs and scantly contribute to the meaning of the lyrics. Furthermore, since we are analyzing the lyrics of all songs for all 5 years, we will keep only unique songs as some songs stay in the top charts for multiple years and consequently would make a lot of words redundant. After this, we count the words by song name and then convert the data frame into the DTM format using `cast_dtm()`. We can see that the object has high sparsity, which is a good sign as it means the vocabulary used in the data frame is rich and it validates the fact that there is variety within the songs.

```{r}
#LDA object with 4 topics
songs_lda_4 <- LDA(songs_dtm, k = 4, control = list(seed = 507))

songs_topics_4 <- tidy(songs_lda_4, matrix = "beta")
songs_topics_4
```

Next, we convert the DTM object into an LDA object with `LDA()` function. Since we do not know how many themes or topics there are, we will start setting the number of objects as 4 then adjust as we perform the analysis. Here, we will analyze the word-topic probabilities using the `tidy()` method with matrix parameter set at "beta". In other words, the algorithm will look at the content of the data set and automatically assign probability of a word belonging to a topic. The resulting data frame is a table with the terms and topics they belong to along with the probability. We will visualize this into a graph for better interpretation.

```{r}
#top 10 terms related to the 4 topics
songs_top_terms_4 <- songs_topics_4 %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>% 
  ungroup() %>%
  arrange(topic, -beta)

#visualize
songs_top_terms_4 %>% 
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered()
```

Setting at 4 topics, the delineation between the topics is still not entirely distinct. The words are quite generic and there is a lot of overlaps. This is normal as these songs are pop songs and they tend to gravitate towards the same vocabulary. However, we can still discern some patterns in the graph.

For example, topic 1 seems to be heavily negative and perhaps materialistic with the word "money". Topic 3 also has many similar words but seems to be more on the sexual content with words like "baby", "girl", "ass", "love". Topic 2 seems to center around passion in an uplifting manner while topic 4 seems to be about passion but more sentimental with words like "feeling" and "beautiful".

Despite the results, the topics are still obscure. We will extend the setting into 6 topics to see whether we can obtain greater clarity.

```{r}
#LDA objects with 6 topics
songs_lda_6 <- LDA(songs_dtm, k = 6, control = list(seed = 507))

songs_topics_6 <- tidy(songs_lda_6, matrix = "beta")

songs_top_terms_6 <- songs_topics_6 %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>% 
  ungroup() %>%
  arrange(topic, -beta)

songs_top_terms_6 %>% 
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered()
```

It seems that even when extending to 6 topics, they continue to be ambiguous. It remains the same that some song sings about passion in various ways and some songs contains a lot of sexualization and materialism. This could be expected for pop culture as these themes are heavily embedded within the history of modern pop culture.

We, therefore, conclude with the setting of 4 important topics for the most popular songs in the recent years, which are materialism (topic 1), charm (topic 2), sensual desire (topic 3), and passion (topic 4) .

## Top songs' topics

Using this model of 4 topics, we can check to which topic the top song of each year pertain. From this we can see whether choosing to sing about a certain topic might make a difference between getting into top 100 and getting the first position of the chart.

```{r}
#topic-word probabilities with 4 topics for top song of each year
tidy(songs_lda_4, matrix = "gamma") %>% 
  inner_join(filter(songs_en, position == 1), by = join_by("document" == "song_name"), keep = TRUE) %>% 
  select(-song_name, -lyrics) %>% 
  group_by(document) %>% 
  slice_max(gamma) %>% 
  arrange(desc(year))
```

Setting parameter "matrix" at "gamma", we obtain a table of songs with the probabilities they pertain to a topic. We are only interested in the top song so we will filter out other songs by making an inner join with the initial data frame that contains song name, position, and other information. Within this data frame, we filter it to contain only songs with position equal to 1 so the inner join will produce a table of number 1 songs with probabilities of belonging to each topic. We then filter the highest probability to a topic of each song to find out the most probably topic that the song sings about.

From this, we see that the top songs pertain to a more upbeat, charming, or sentimental passion theme. We also saw from before that these songs contain less profanity, are either sentimental, metaphorical, or energetic. Perhaps, these are the ingredients for making top songs in the modern pop culture. We can further extend this analysis to include songs from top 10 for each year to examine this idea.

```{r}
#visualize count of each of the 4 topic on the top 10 song of each year
tidy(songs_lda_4, matrix = "gamma") %>% 
  inner_join(filter(songs_en, position <= 10), by = join_by("document" == "song_name"), keep = TRUE) %>% 
  select(-song_name, -lyrics) %>% 
  group_by(document) %>% 
  slice_max(gamma) %>% 
  arrange(desc(year)) %>% 
  ungroup() %>% 
  count(topic)  %>% 
  ggplot() +
  geom_col(aes(n, reorder(as.factor(topic), n))) +
  xlab("count") +
  ylab("topic")
```

Expanding the analysis to include more songs from top 10, we find that topic 2 and topic 4 still dominate. This reaffirms the hypothesis that songs featuring lyrics about passion, energy, and charm could obtain better success compared to others. However, it is important to acknowledge that a song's success can be influenced by a multitudes of factors, such as its melody, the reputation of the artist singing the song, and so on. Thus, while lyrical content can have an important role, it is certainly not the singular decisive component to the success of a song.

# Summary

In this analysis, we first collected the information about the top 100 songs from 2019 to 2023 from The Billboard Year End Hot 100 charts on Wikipedia. Using Genius' API, we were able to acquire the lyrics of the songs. The data set was then cleaned by removing songs that are not in English or with no correct lyrics found. Following this, we performed the initial layers of text analysis which are splitting and tokenizing. In this step, we further refined the data by correcting words that are misspelled due to the pronunciation of pop culture. The data frame is finally filtered by non stop words for sentiment analysis.

From sentiment analysis, we learned that in the recent period of 5 years, song's with more negative words dominate while positive songs had an uptick in 2021 but then descended. We then looked into the most common negative words and positive words used in the songs and found that most negative words were obscenities. This in turn gave a lot of penalties to the songs so in reality the songs might not be very negative. Furthermore, there might negation in the sentence that contains the negative words, which would make the songs even less negative in meaning. We then moved on to looking at the top song of each year to see what sentiments they convey. There was a healthy mix of negative and positive words in these top songs but what made them stand out from the rest was that the words are more specific, nuanced and sentimental. Finally, we looked at whether the most successful artists leaned more towards singing negative or positive songs and found that similar to the overall trend, they indeed had more negative songs.

In the subsequent section, we tried to understand more about the topic and the context that the songs sing about by performing a term frequency analysis. We learned that the top songs tend to stay around a certain range of words and there is a chance that very lengthy or wordy song might not be very popular. Through looking at the tf-idf values, we were able to identify some possible themes that these popular songs sing about. These theme include women, intoxication, relationship, spiritual belief or religion, and Christmas. We proceeded to look at the top songs to see whether they also sing about these themes or diverged from them. We found that some coincided while others did not.

We then explored the context and meaning of the songs further by looking at pairs and groups of words. We began with pairs of words, or bigrams, and confirmed some common themes that we found before. We also saw some new common themes emerging for example desires. The bigrams also allowed us to see clearer in which context the themes were. For instance, women is indeed a common themes but there are different context in which they were sung about. Some were positive and some were negative. We also found that relationship or love was sung about in a more sorrowful and somber setting. Trigrams, however, did not offer much information other than some popular terms that were used and a confirming some topics that were found using individual words and bigrams. Lastly, examining bigrams of the annual top songs helped confirm the hypotheses about the context of the songs we previously made in term frequency analysis.

Ultimately, we employed a topic modelling technique with LDA algorithm to categorize possible themes of the songs. We found that with our data set 4 topics were an appropriate number. These topics have overlapping words and can be split into 2 big categories. However, there are subtle differences between them. There are 2 topics seemingly relate to passion. One of which is in an uplifting and charming way while the other is more sentimental. The other 2 topics are more on the negative side with a lot of profanity used. One of the 2 seems to talk more about materialistic things like money while the other has a more sensual provocation.

# Limitation

There are certainly a lot of limitations in the analyses that we performed. Natural language is inherently messy and pop music is even more so with abundance of slang and subcultural terminology. To have a better, more accurate analysis, we would need to be able to clean the data more diligently. We corrected a large portion of words that missed out the ending letter but there were still many words that are sung with a different variations of pronunciation.

Furthermore, using lexicons for sentiment analysis introduced a lot of deviation from the actual intended sentiment of the lyrics. Using lexicons on individual words failed to appropriately assign sentiment value for negative or positive words when paired with a negation term such as "not", "no", "never", etc. Some value assignments from the lexicons were also controversial.

While looking at pairs and groups using n-grams helped us understand the context, it still did not demonstrate the entire picture. In natural language, some words can be related to each other but they might not be placed adjacently, thus, rendering the n-grams improper. It is possible to look at longer sequence n-grams but then we would trade off a lot of computation power and make the analysis counterproductive.

To improve the analysis, we would need more sophisticated method such as large language models to be able to put the whole lyrics of the songs into context and interpret their meaning accordingly. We would also need to use a translation model to translate songs in other language and English songs that have some lyrics in other languages in order to avoid loss of information.

# Conclusion

The world in the last 5 years was eventful and the pop music culture certainly did not differ. Our analysis revealed an array of various themes that were sung about in the top songs. We saw a rising trend in negative songs but we also recognize that it might not be the case for reality as the tools we used had limitations against the complexity of language. To gain a better understanding of how the trend of pop music is evolving, future researches can benefit from analyzing a larger data set with more historical data of the top popular songs. Additionally, it is crucial to include information from different sources rather than one singular source used in this analysis.
