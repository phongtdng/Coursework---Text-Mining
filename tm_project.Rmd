---
title: "Popular Songs' Lyrics Analysis"
author: "Phong Duong"
date: "2024-02-14"
output: html_document
---

# Introduction

The last 5 years have been eventful around the world. From Brexit in 2019, to the global spread of COVID-19 in 2020, the 2020 Olympic game in 2021, the Russia-Ukrain war in 2022, and the recent record of global temperature in 2023, these are just a few major events that happened. Undoubtedly, many of these events have left a permanent mark in the mind of people, some even changed their behaviors everlastingly. Different people respond differently to these events and changes. In this project, we will explore this reaction through the lens of pop music.

Pop culture has always been an important device that mirrors societal attitude and expression. One powerful tool that portrays well the influence of pop culture on the public is music. Music reflects well emotions and belief of people. By examining the general's choice of pop songs, we can obtain valuable insights on cultural trends and collective sentiments of the society.

In this analysis, we will analyse lyrics from the top popular songs from 2019 to 2023 to hopefully get a glimpse of the emotional experiences and the important topics that are the focal point of the community of music listeners. The songs are curated from Billboard annual top 100 singles and therefore might not be inclusive to all listeners but nevertheless is representative to a large part of the music community (stats?).

# Library

```{r}
# #installing packages if needed
# install.packages("tidyverse")
# install.packages("rvest") #for scraping data from static web pages
# install.packages("xml2") #for reading html files of the web pages
# remotes::install_github("giovanni-cutri/geniusr") #api of genius website - contains lyrics and many information about songs and artists
# install.packages("cld3") #for detecting language
# install.packages("tidytext")
# install.packages("hunspell") #detect misspelling
# install.packages("ggpubr") #combine ggplots into 1
# install.packages("igraph") #prepare network graph
# install.packages("ggraph") #make network graph
```

```{r}
library(tidyverse) 
library(rvest) 
library(xml2) 
library(geniusr) 
library(tidytext)
library(hunspell)
library(ggpubr)
library(igraph)
library(ggraph)
```

Note: the package `geniusr` is an R package for using Genius API. The package is originally created by ewenme but there is an issue for function `get_lyrics`, which has been fixed by giovanni-cutri so we will use their version of `geniusr` package.

# Data Collection

The Billboard Year End Hot 100 singles compiles the top performing singles of the United States based on both physical and digital sales. Although the charts are posted on the website of Billboard, in this analysis, we are getting the data from Wikipedia since it has a much better format for scraping the data and it is open-source. We begin the data collection process by making a test scrape for the year 2023.

## Test Scrape 2023

```{r}
#url of wikipedia page for top songs 2023
billboard100_2023 <- "https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_2023"

#check and clean scraped data and put into a readable format (dataframe)
read_html(billboard100_2023) %>% 
  xml_find_all("//table[contains(@class,'wikitable')]/tbody/tr[td]") %>% 
  xml_text() %>% 
  str_replace_all("\n", "") %>% 
  str_replace_all("\"", "%") %>% 
  as_data_frame() %>% 
  separate_wider_delim("value","%", names = c("position", "song_name", "artists"))
```

The table containing the information that we need is a unique `<table>` element with the `class = 'wikitable'` and all the pages for other years have the same format so we can use the same syntax to scrape songs from all the years that we are interested in.

## Scrape All Songs

```{r}
#interested years
years <- c(2019:2023) 

#helper function to streamline the scraping process
get_top_songs <- function(year){
  url <- paste0("https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_", year)
  
  #save the scraped and cleaned data into a dataframe like previously
  df <- read_html(url) %>% 
  xml_find_all("//table[contains(@class,'wikitable')]/tbody/tr[td]") %>% 
  xml_text() %>% 
  str_replace_all("\n", "") %>% 
  str_replace_all("\"", "%") %>% 
  as_data_frame() %>% 
  separate_wider_delim("value","%", names = c("position", "song_name", "artists"))
  
  df <- df %>% mutate("year" = year) #add a year column
  
  return(df)
}

#applying the helper function to a vector and returning a dataframe
all_top_songs <- map_dfr(years, get_top_songs)

all_top_songs
```

The final data frame has 500 rows, which is in accordant to 5 charts of the 5 years period (2019-2023) so the scraping should have gone correctly. The next step will be to get the lyrics for these songs in order to create a complete data frame. We will use Genius API to get the songs' information and lyrics. We will use the library `geniusr` which facilitates the use of Genius API.

**Important**: To reproduce this report using `geniusr` package, it is important to follow these steps from the guide of the package:

1.  [Create a Genius API client](https://genius.com/api-clients/new)
2.  Generate a client access token from the [API Clients Page](https://genius.com/api-clients)
3.  Calling `genius_token()` and enter your Genius Client Access Token

The full guide to the `geniusr` package is on this [GitHub page](https://github.com/ewenme/geniusr?tab=readme-ov-file)

## Get Lyrics

```{r}
genius_token() #call and enter Client Access Token to authenticate to use Genius API 
```

```{r}
#helper function to get lyrics of a song
just_lyrics <- function(artist, song){
  #search for id of song based on song name and name of first artist
  id <- search_song(paste(song, str_extract(artist, "\\w+( [A-Z]\\w+)?")))[1,1] %>% pull()
  
  #get lyrics based on id
  get_lyrics_id(id) %>% 
    .$line %>% 
    paste(., collapse= " ")
}

#add lyrics column to the data frame of songs from before
all_songs_lyrics <- all_top_songs %>% 
  mutate(
    lyrics = mapply(just_lyrics, artists, song_name)
  )

#save the complete data frame into a csv file for easy retrival for analysis later
write_csv(all_songs_lyrics, "all_top_songs_lyrics.csv")
```

One way to get lyrics of a song using the `geniusr` package is to use the function `get_lyrics_id()` with a singular parameter `id` . This `id` can be retrieved by using the function `search_song` and the resulting table's first cell ([1,1]) is the id of the song. We built a helper function to facilitate the lyrics retrieval.

It took 31 minutes to scrape all the lyrics for the 500 songs so we will save the data into a csv file to avoid scraping every time we perform analysis. *This might make the reproduction of the analysis faulty to changes added after the publish date of the project.*

# Data Cleaning

```{r}
all_songs_lyrics <- read.csv("all_top_songs_lyrics.csv") %>% 
  drop_na()

wrong_lyrics <- c("Ritmo (Bad Boys for Life)", "My Ex's Best Friend", "Hrs and Hrs")

all_songs_lyrics <- all_songs_lyrics %>% 
  filter(!song_name %in% wrong_lyrics) 
```

The lyrics scraped are not perfect because some searches returned id of a remix of the song or a different language version of the song. Therefore, we have to find and clean them. After going through the lyrics of 500 songs, I found 3 songs with faulty lyrics. I decided to exclude them from the list since at this point I had already reached the limit from Genius API.

```{r}
songs_en <- all_songs_lyrics %>% 
  mutate(
    lang = cld3::detect_language(lyrics)
  ) %>% 
  filter(lang == "en")
```

There are 25 songs in other languages than English so we either have to exclude them or translate them into English for the analysis method that we will use in this project. The detection was done by the `cld3` package - a neural network model for language identification. It was mentioned that the version used at the time of this project was still experimental so reproduction might produce different results. Another option to do this task could be using DeepL API. The package `deeplr` is available to facilitate the use of DeepL API and has functions for detecting and translating languages. However, DeepL free API is extremely limited and subscription is expensive. Therefore, for the scope of this project, we will use `cld3` package and exclude songs that are not in English.

# Split and Tokenize

```{r}
songs_en_st <- songs_en %>% 
  unnest_tokens(word, lyrics)
```

As per usual with most case of analysing songs of pop culture, there are many potential issues for the analysis with the word used in these songs. In our case, there are many slang words that are not recorded in the dictionary and words that are sang differently for the purpose of rhyming or simply style. Some examples of these words are "nothing" becoming "nothin", "fighting" becoming "fightin", and so on. We will try to clean these as much as possible but it is frankly very messy to handle. There are packages that can help correcting the misspelling (e.g., `textclean`, `hunspell`) but these are usually not accurate for slang and words from pop culture. Stemming and lemmatization can help but at the same time might take away valuable information or incorrectly stem or lemmatize (for example, some packages reduce "is" to "i" or give errors to slang and words related to pop or internet cluture).

```{r}
misspelling_dict <- songs_en_st %>% 
  select(word) %>% 
  distinct() %>% 
  mutate(misspelling = hunspell_check(word)) %>% 
  filter(misspelling == FALSE) %>% 
  #important misspelling are verb-ing words so we will correct by adding g at the end of word
  mutate(ing_word = str_detect(word, pattern = "\\w+in$")) %>% 
  filter(ing_word == TRUE) %>% 
  mutate(correction = paste0(word, "g")) %>% 
  #double check again to include only words correctly corrected
  mutate(misspelling_2 = hunspell_check(correction)) %>% 
  filter(misspelling_2) %>% 
  select(word, correction)
misspelling_dict
```

We will create a dictionary for misspelled words from the songs' lyrics of the data set. We will use the `hunspell` package for identifying the misspelling. Most of the identified misspelled words are either verbs ending in "ing" (present participle or gerund) and names or words from other languages or slang. Since names and pop culture words contribute meaning to the song and are not entirely affected by the analysis, we will only correct the verb-ing words so later they can be identified by the lexicons. This was done by detecting misspelled words ending with "in" then adding "g" to the of the word. They are checked again by the `hunspell_check` to filter out other words that also end with "in" but are not verb-ings.

```{r}
songs_cleaned <- songs_en_st %>% 
  left_join(misspelling_dict, by = join_by(word)) %>% 
  mutate(correct_word = ifelse(is.na(correction), word, correction)) %>% 
  select(-word, -correction) %>% 
  rename(word = correct_word)

songs_cleaned
```

We prepare the final, cleaned version of the data set by joining the misspelling dictionary data frame with the original data frame then create a new column that takes the correction form of misspelled words and original form if they are not in the dictionary.

# Filter Stop Words

```{r}
songs_en_filtered <- songs_cleaned %>% 
  anti_join(stop_words)

songs_en_filtered
```

# Lexicon-based Sentiment Analysis

In the following section, we will explore the sentimental themes of the popular songs from 2019 to 2023 to uncover insights about music listeners, as least for the pop culture, and how they relate or reflect the phenomena happening during these years. Since the uneventful arrival of COVID-19, there was a range of emotions displayed on social media, news, and public opinion sharing platforms. The pandemic claimed many lives and forced most countries into isolating people, thus, we could expect a rise in more negative songs about loneliness or sadness. It is also possible that songs about courage and felicity will rise instead as people try to cope by listening to positive songs.

```{r}
sa_df_bing <- songs_en_filtered %>% 
  inner_join(get_sentiments("bing")) %>% 
  group_by(year, song_name, artists) %>% 
  count(sentiment) %>% 
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% 
  mutate(sentiment = positive - negative) %>% 
  mutate(sentiment_label = ifelse(sentiment == 0, "neutral", ifelse(sentiment > 0, "positive", "negative")))

sa_df_bing$sentiment %>% summary()
```

```{r}
sa_df_afinn <- songs_en_filtered %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(year, song_name, artists) %>% 
  summarise(sentiment = sum(value)) %>% 
  mutate(sentiment_label = ifelse(sentiment == 0, "neutral", ifelse(sentiment > 0, "positive", "negative")))

sa_df_afinn$sentiment %>% summary()
```

We are using 2 lexicons "bing" and "afinn" to measure the sentiments of words of the songs. With "bing", a song is classified as "positive" if the net value of positive words subtracting negative words is greater than 0 (positive - negative \> 0), "negative" if it is below 0 (positive - negative \< 0), and "neutral" otherwise (positive - negative = 0). With "afinn", this sentiment label is categorized by the sum sentimental values of words with the same criteria for "bing".

A brief descriptive analysis on the sentiment attribute shows that more than half of the songs carry negative connotation in their lyrics with means of -8.3 and -16.8 and medians of -6 and -5 for "bing" and "afinn" repsectively. It also shows that the negative notation has a peaked value almost double the positive (-83 compared to 42 for "bing" and -325 compared to 163 for "afinn"). This means that the song with the highest negative connotation has almost double the amount of negative words or negativity than the top positive song. We can see this more clearly with the box-plots below.

```{r}
#box-plot for sentiment column
ggarrange(
  ggplot(sa_df_bing) + geom_boxplot(aes(y = sentiment)),
  ggplot(sa_df_afinn) + geom_boxplot(aes(y = sentiment)),
  labels = c("bing", "afinn")
)
```

## Song sentiment over the years

```{r}
#combine afinn and bing data set to compare song sentiment over the years
oty <- bind_rows(
  sa_df_afinn %>% mutate(method = "afinn"),
  sa_df_bing %>% select(-negative, -positive) %>% mutate(method = "bing")
)

oty %>% 
  group_by(method, year, sentiment_label) %>% 
  count() %>% 
  ggplot() +
  ggalt::geom_xspline(aes(year, n, color = sentiment_label)) + #geom_xspline for smooth line
  xlab("year") +
  ylab("number of songs") +
  facet_wrap(~method, ncol = 1, scales = "free_y")
```

Although the 2 lexicons give different results on the overall sentiment of songs, they both seem to be in accordance on the rise and fall of negative and positive songs after 2020. In 2021, the number of negative songs rose while the number of negative songs plummeted. This trend, however, reserved from 2021 to 2023, where negative songs start to ascend and the positive songs went down in number. From 2019 to 2020, it seems that using "bing" gives us a fall in negative songs and an increase in positive songs but with "afinn" this pattern is inverted. Despite the difference in trend, the increase or decrease are relatively small for both graphs. Both also agree on the little number of neutral songs, which is perfectly normal for music since songs tend to express a lot of emotions.

It is difficult to determine whether our initial or second hypothesis about the music listening trend during the pandemic was correct since the 2 lexicons produced different results for the period 2019 to 2020. The number of negative songs outweighed the number of positive songs but it is unclear whether it is a perpetual trend with pop culture or a singular phenomena within this period. However, the trend after 2020 tells a much clearer story. The COVID-19 pandemic started around December 2019 and began to spread worldwide in early 2020. Following this pandemic was a series of lock down in populated cities and was lifted after mid 2021 for the majority of places. The end of the quarantine allowed reunion between loved ones and represented a signal of the waned sign of COVID-19. Thus, this gave rise to celebration and positive sentiments, which seem to be reflected accordingly in the graphs. The graphs then show a surge of popularity of negative songs in 2022 and 2023. This could reflect the sentiment against the series of misfortune events that happened such as the war in Ukraine, the sharp rise of inflation, and various droughts and floods in many regions.

## Most common positive and negative words

We learned before that some songs could be extremely negative while very positive songs do not contain as many positive words. There also seems to be a permanent trend of pop culture in that negative songs dominate in number in the charts in all years. We will explore more the vocabulary used in the songs to understand more why these phenomena happen.

```{r}
common_words_bing <- songs_en_filtered %>%
  inner_join(get_sentiments("bing")) %>% 
  count(word, sentiment, sort = TRUE)

ggplot(common_words_bing %>% filter(n > 50)) +
  geom_col(aes(reorder(word,n), n, fill = sentiment)) +
  coord_flip() +
  facet_wrap(~sentiment, scales = "free_y") +
  xlab("frequency") +
  ylab("word")
```

It seems that positive words concentrates on the word "love" while negative words spread out on various words. The majority of the negative word use is curse words. However, some of these words can carry different sentimental notation other than negative depending on the context in which it is used. For example, "shit" and "damn" could be an affirmation of positive feeling when paired with words like "good". We will analyse this on a deeper level in another section.

Some interesting negative words are "miss", "lost", "lonely", "die". Although they are common terminologies that are used in various situations, they are very related to the mishaps of the major events that happened during this time period. The prolonged quarantines could be a reason why "miss" and "lonely" got in the top popular words in the songs and the deaths due to COVID-19 and the wars might have contributed to the high use of "lost" and "die".

On the positive chart, the words seem quite common and general. We were expecting more words that indicate hope or courage but they did not make it to the top here.

```{r}
common_words_afinn <- songs_en_filtered %>%
  inner_join(get_sentiments("afinn")) %>% 
  count(word, value, sort = TRUE) %>% 
  mutate(sentiment = case_when(
    value < 0 ~ "negative",
    value > 0 ~ "positive",
    TRUE ~ "neutral"
  ))

ggplot(common_words_afinn %>% filter(n > 50)) +
  geom_col(aes(reorder(word,n), n, fill = sentiment)) +
  coord_flip() +
  facet_wrap(~sentiment, scales = "free_y") +
  xlab("frequency") +
  ylab("word")
```

With "afinn" lexicon, we get a similar result. Most popular negative words are curse words while popular positive words concentrate on "love" and "yeah". However, words like "hope" and "care" do appear to have some importance. "God" is also an interesting word that could indicate how the situations might have brought out people's need for faith.

We will next look at the common words by year to have a clearer picture of each year.

```{r}
common_words_by_year_bing <- songs_en_filtered %>%
  inner_join(get_sentiments("bing")) %>% 
  count(year, word, sentiment, sort = TRUE)

ggplot(common_words_by_year_bing %>% filter(n> 30)) +
  geom_col(aes(reorder(word,n), n, fill = sentiment)) +
  coord_flip() +
  facet_wrap(~year, scales = "free_y") +
  xlab("frequency") +
  ylab("word")
```

Looking by the year, it seems that there are some evidence supporting our earlier hypothesis. In 2020 and 2021, "lonely" and "miss" are in the top common words used in these popular songs. This could suggest that the pandemic and the lock down produced some nostalgic effect for people. Some words like "love", "shit", "bitch", "fuck" seem to be time-less, in that they appear in all years. It is also interesting that in 2019 and 2020, usage of sentimental words seemed to spread out more while from 2021 to 2023, and especially in 2022, certain words are overly repeated. Perhaps, 2022 was not a very creative year in song writing. Finally, although using "afinn" gives longer list of top words, their pattern are similar to using "bing". The results of using lexicon affin are displayed below.

```{r}
common_words_by_year_afinn <- songs_en_filtered %>%
  inner_join(get_sentiments("afinn")) %>% 
  count(year, word, value, sort = TRUE) %>% 
  mutate(sentiment = case_when(
    value < 0 ~ "negative",
    value > 0 ~ "positive",
    TRUE ~ "neutral"
  ))

ggplot(common_words_by_year_afinn %>% filter(n> 30)) +
  geom_col(aes(reorder(word,n), n, fill = sentiment)) +
  coord_flip() +
  facet_wrap(~year, scales = "free_y") +
  xlab("frequency") +
  ylab("word")
```

## Top Songs

```{r}
top_songs_bing <- songs_en_filtered %>%
  filter(position == 1) %>% 
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) 
  
ggplot(top_songs_bing) +
  geom_col(aes(reorder(word,n), n, fill = sentiment)) +
  coord_flip() +
  facet_wrap(~sentiment, scales = "free_y") +
  xlab("word") +
  ylab("frequency")
```

We have seen the over sentiments of all songs previously, perhaps the top songs might convey different emotions than the rest that make them stand out more. We will look at this by filtering out the data set to have only songs at the first position in the chart.

For the top songs, there are positive words in common to all songs such as "love", "loving", "trust" and "woo". However, we also see some more specific and more positive words such as "happier", "perfect", "perfectly", and "glitter". On the negative side, they also use profanity such as "shit" and "hell". "shimmer" seems to be considered negative in bing lexicon but the word's definition does not exactly coincide so we will not consider it. It is interesting, however, that the negative words are also more specific and deeper such as "drowning" and "cold".

```{r}
top_songs_afinn <- songs_en_filtered %>%
  filter(position == 1) %>% 
  inner_join(get_sentiments("afinn")) %>% 
  count(word, value, sort = TRUE) %>% 
  mutate(sentiment = case_when(
    value < 0 ~ "negative",
    value > 0 ~ "positive",
    TRUE ~ "neutral"
  ))

ggplot(top_songs_afinn) +
  geom_col(aes(reorder(word,n), n, fill = sentiment)) +
  coord_flip() +
  facet_wrap(~sentiment, scales = "free_y") +
  xlab("word") +
  ylab("frequency")
```

Using afinn lexicon, we further see that the negative words used in the top songs carry more criticism with words like "faking" or "fake". We also see very emotional theme with "empty", "lost", "broken", and "cheated".

For now, it is still unclear what topics that the songs sing about. We have only seen that these songs seem more emotional and use less profanity to express the bad feelings while using more specific words to describe good feelings. We will later on examine the context of songs better with term frequency and n-gram analysis.

## Top Artists

We have seen that some artists can go very negative or positive in their song writing. We have also seen before that negative songs seem to dominate in popularity in the pop charts. Does this suggest that an artist might have a better chance at getting more songs in the top positions by choosing more negative songs? We can probe this hypothesis by looking at the top artists, ones that had the most songs placed in these top 100 boards, and check their ratio of positive versus negative songs.

```{r}
#make a data frame of top 10 artists (with most songs in the charts) of the period
artists_sa <- bind_rows(
  sa_df_afinn %>% group_by(artists) %>% count(label = sentiment_label) %>% mutate(method = "afinn"),
  sa_df_bing %>% group_by(artists) %>% count(label = sentiment_label) %>% mutate(method = "bing")
) %>%
  group_by(method, artists) %>% 
  mutate(total_songs = sum(n)) %>% 
  group_by(method) %>% 
  slice_max(n=20, order_by = total_songs, with_ties = TRUE) 

#visualise  
artists_sa %>% ggplot() +
  geom_col(aes(reorder(artists, total_songs), n, fill = label)) +
  coord_flip() +
  facet_wrap(~method, scales = "free_y") +
  xlab("Top artists") +
  ylab("number of songs")
```

Using "afinn" and "bing" gives us different results. However, the common pattern is clear. Most of these top artists had a favorite pick of negative songs. "Luke Combs", "Ariana Grande", and "Post Malone" are the few that made their fame by singing more positive songs, according to "afinn". However, the messages of their songs might not so much be negative in reality if taken into account the context of the whole song. The results here only indicate that the words employed in those songs are defined to carry negative notions by the lexicons. An educated guess could be that their lyrics contain a lot of profanity, which is very much normalized in pop culture. We will next examine on a deeper level of the words used and related word statistics to detect important words.

## Bonus: Most positive vs most negative songs

```{r}
#most positive songs from each year
most_pos <- sa_df_afinn %>% 
  group_by(year) %>% 
  slice_max(sentiment)

#most negative songs from each year
most_neg <- sa_df_afinn %>% 
  group_by(year) %>% 
  slice_min(sentiment)

#visualise
ggplot() +
  geom_col(data = most_pos, aes(year, sentiment), fill = "orange") +
  geom_col(data = most_neg, aes(year, sentiment), fill = "blue") +
  coord_flip() +
  geom_text(data = most_pos, aes(x = year, y = 0, label = song_name), 
            hjust = "left", nudge_y = 5) +
  geom_text(data = most_neg, aes(x = year, y = 0, label = song_name), 
            hjust = "right", nudge_y = -5)
```

We have seen from the previous section the most common positive and negative words throughout 2019 to 2023 and also in each year. We will now look into the songs with the highest positive and negative net scores to see the development of emotional ranges in this time period. Like we saw in the beginning, the top most negative song had a much higher score than the most positive song. We can see that it applies for almost all of the years with the exception of 2020 where both songs have similar scores. The peak of positivity seems to dwindle after 2020 while for negativity it fluctuates. We can look into the lyrics of these songs to paint a clearer picture of the story they might be telling.

```{r}
songs_en_filtered %>% 
  filter(song_name %in% most_pos$song_name) %>% 
  group_by(song_name) %>% 
  count(word) %>% 
  slice_max(n, n = 10) %>%
  ungroup() %>% 
  ggplot(aes(n, reorder(word, n))) +
  geom_col() +
  facet_wrap(~song_name, scales = "free_y") +
  xlab("frequency") +
  ylab("word")
```

From looking at the top most frequent words of these songs, it seems that some common themes are love ("Flowers" and "Lose You to Love Me") and beauty ("Beautiful" and "Way 2 Sexy"). "To the Moon" seems to have more of catchy, positive sounds like "yeah" and "ha" without a clear story.

Love is a compelling theme for powerful sentiments, it can be either really positive but also really negative. "Flowers" carries a lot of nostalgic notions with words like "remembered", "wanna", and seems to have a vivid story with action words like "cry", "write", "talk", "dancing", "leave", "hold" and "hands", coupled with nouns like "sand", "hours", "flowers". The whole lyrics of song portray clearly an overcome of a sad past romance and a new focus on self-love so it makes sense that the song has a positive net score of sentiment. "Lose You to Love Me", on the other hand, seems to have gotten a high score on positiveness due to high frequency of the word "love" and "yeah". From the name of the song and words like "promised", "fell", and "adored" being used in past tense make a clear story of moving on from a past loving relationship. However, other top appearing words like "hate", "burn", "killing, and "fires" could suggest a less positive overall sentiment that was compensated by high frequency of the positive score of "love" and "yeah". To further understand the stories of the songs, we would need to analyse pairs and groups of words, which will be detailed in later sections.

"Beautiful" and "Way 2 Sexy" are also in the same theme but seem to differ in their message. "Beautiful" seems to convey a clearer positivity with use of words such as "angel", "amazing", coupling with words like "naked" and "imperfections", which probably talks about beauty despite flaws. "Way 2 Sexy", however, seems to have gotten a high score on positiveness due to repeated use of words like "sexy", "yeah", and "woah". The rest of the top words seem to talk about "fame", money ("cash"), and convey a more materialistic message with "ice", "chain", and "bags". The song certainly could be positive overall but further look at word pairs and groups would make the message of the song clearer.

```{r}
songs_en_filtered %>% 
  filter(song_name %in% most_neg$song_name) %>% 
  group_by(song_name) %>% 
  count(word) %>% 
  slice_max(n, n = 10) %>%
  ungroup() %>% 
  ggplot(aes(n, reorder(word, n))) +
  geom_col() +
  facet_wrap(~song_name, scales = "free_y") +
  xlab("frequency") +
  ylab("word")
```

The negative songs, on the other hands, portray a very vague story with their most frequent words. Most of these words are swear words and carry little meaning by themselves. "Blueberry Faygo" is the only song of the 5 that has high diversity of top words and sequentially gives us more information about the song's topics. With words like "shooting", "poured", "millions", and named entities "draco" and "blueberry faygo", it is probably that the songs sings about living this certain kind of lifestyle with "draco" as an important figure, perhaps one of the singers or producers of the song, and "blueberry faygo" as a metaphor for certain thing about this lifestyle. Like stated previously, it is conceivably better to analyse these songs by pair or word groups to understand more what the topic or message of these songs is.

# Term Frequency Analysis

From the sentiment analysis, we learned that the pop culture seems to favor negative words, particularly profanity. Some of the words in these popular songs, both positive and negative, seem to have long tail tendency with some common words topping the chart of frequency. We also looked at some top sentiment words of songs to understand what emotional message that the songs tried to deliver. Finally, we learned that the majority of the top artists in the music charts made it to the peak by writing more negative songs. In this section, we will dive deeper into the content of the songs to discover what are the common objects of attention in the pop music community.

## Word Count

```{r}
song_words <- songs_cleaned %>% 
  count(position, year, song_name, word, sort = TRUE) %>% 
  group_by(year, song_name) %>% 
  mutate(total_words = sum(n),
         term_freq = n/total_words,
         position_level = ifelse(position <= 10, "Top 10", "Top 100")) %>% 
  ungroup()

#word count distribution
ggplot(song_words) +
  geom_histogram(aes(total_words, fill = position_level)) +
  xlab("Total word count per song") +
  ylab("Frequency")
```

Most songs tend to be around 3 to 4 minutes in length. This is due to how vinyls were made in the 1800s and 1900s, which limited the the length of music that can be written onto them ([Vox](https://www.vox.com/2014/8/18/6003271/why-are-songs-3-minutes-long)). Vox also explained that although the evolution of technology allowed songs to recorded for a longer period of time, the radio and digital media industry influenced music to stay short in order to be able to be enter the mainstream.

Undoubtedly, with limited amount of time, the length of songs' lyrics also stay within a certain range. We can see this from the graph above. Most songs tend to have around 300 to 600 words. Top 10 songs are also mostly in this range. Thus, we can hypothesize that lengthy and wordy songs might have less chances of making it to the top 10.

```{r}
ggplot(song_words) +
  stat_summary(aes(year, total_words),
               fun.y = "mean",
               geom = "bar") +
  facet_wrap(~position_level)
```

This phenomenon does not seem to change through time. Songs seem to stay consistent in lyrics length in all the years and top 10 songs seem to be slightly shorter than the top 100.

## Term Significance

```{r}
ggplot(song_words, aes(term_freq)) +
  geom_histogram() +
  xlim(0, 0.15)
```

Similar to novels, songs seem to share a long tail distribution in word frequency. Some words are more common and appear more frequently and there are words that make the songs more unique. We will explore them further on the analysis.

```{r}
ggplot(song_words, aes(term_freq)) +
  geom_histogram(show.legend = FALSE) +
  xlim(0, 0.05) + 
  facet_wrap(~year, scales = "free_y")
```

We can also confirm that this phenomenon is steady throughout each year by looking at the graph above of the word distribution by year. So, some words have higher frequency compared to the rest. By looking at them, we can better understand the important words of a song and consequently what the song is about. We will next analyze the term frequency for each year to find out the words the characterize them.

```{r}
top_term <- song_words %>% 
  group_by(year) %>% 
  slice_max(term_freq, n=10) 

ggplot(top_term) +
  geom_col(aes(term_freq, reorder(word, term_freq))) + 
  ylab("word") +
  xlab("frequency") +
  facet_wrap(~year, scales = "free_y")
```

It seems that some significant words are vocal sounds (e.g., "ooh", "la", "bam", etc.). Although they contribute to the songs vocally, they do not carry much semantic meaning and therefore we will filter them out to get a better picture of the songs' messages.

```{r}
vocal_sounds <- c("ah", "ody", "boaw", "ooh", "oh", "bam", "da", "na", "woah", "yaka", "la", "doo", "ding", "dong", "buh")

top_term <- song_words %>%
  filter(!word %in% vocal_sounds) %>% 
  group_by(year) %>% 
  slice_max(term_freq, n=10) 
  
ggplot(top_term) +
  geom_col(aes(term_freq, reorder(word, term_freq))) + 
  ylab("word") +
  xlab("frequency") +
  facet_wrap(~year, scales = "free_y")
```

After weeding out the vocal sounds, we can see that there are some common themes that characterize the top songs for each year. "i" and "you" appear in all years, suggesting that the top songs tend to have a first person perspective. This could make the song more personal and better connect with the listeners. The context of the songs, however, are still quite hazy and not distinctive enough to draw conclusions on the relevant topics of the years. We will now compute the inverse document frequency to combat this issue.

```{r}
#add more words and sounds that do not have semantic meaning
vocal_sounds_extended <- c(vocal_sounds, "blrrrd", "o","tu", "bo", "teh", "yuh", "lo", "ough", "eno", "sha", "taki", "que", "grrah", "ma", "dum", "onely", "nah", "ee", "p", "ba", "ahh", "mhm", "ayy", "uh", "huh", "woo", "mmm", "mm", "bop", "yeah")

#some songs are in the top charts for several years and tf-idf do not work with group() so we will create a function to do this per year
map_tf_idf <- function(y) {
  df <- song_words %>% 
    filter(year == y) %>% 
    filter(!word %in% vocal_sounds_extended) %>%
    bind_tf_idf(word, song_name, n)
}

#binding all the years to create a single dataframe with all the years
songs_tf_idf <- map_dfr(c(2019:2023), map_tf_idf)
songs_tf_idf

#visualising top relevant words of each year
songs_tf_idf %>% 
  group_by(year) %>%
  slice_max(tf_idf, n = 15) %>%
  ungroup() %>% 
  ggplot(aes(tf_idf, reorder(word, tf_idf))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~year, scale = "free") +
  labs(x = "tf-idf", y = NULL)
```

Some songs are present in the top 100 charts in multiple years, which will create issue when using the function `bind_tf_idf()` (giving negative idf values). Therefore, we will need to group them by year. However, the function `bind_tf_idf()` ignores groups so we have to do it separately. In the code, a helper function was created which takes our original data frame of words with count and filters it by an input year and the meaningless sounds, then finally creates new "tf", "idf", and "tf_idf" columns with `bind_tf_idf()`. The output of this function is a data frame of songs and their filtered words for one year. We then use the function `map_dfr()` to apply the function on an array of years to ultimately obtain a data frame of songs with "tf", "idf", and "tf_idf" values that are grouped by year.

We see that although each year some words stand out more than other, we can still detect some popular theme for all years. For example, there is a tendency towards including a woman figure in the songs with words such as "girlfriend", "roxanne", "woman", "she" and "gaga". Words about intoxication are also very relevant in the recent years with the appearance of "tripping", " margarita", and " wasted". Relationship is also one theme that is distinguished from the appearance of words such as "girlfriend", "heartless", and "heartbreak". Words like "hopes", "lord", "amen", "holy", and "karma" also signify the importance of faith or spiritual belief. These themes are, perhaps, not only important for the recent years but have been dominant throughout history in music and other literature. They tend to invoke emotions that people are naturally drawn to and therefore do not surprisingly come as important topics.

It is also important to point out that from 2021 to 2023, Christmas songs seem to make a come back to the top as words like "christmas", "jolly", "holly", "jingle" and "bell". Christmas is centered around reunions with family and friends, something of which people were deprived during the series of lock down due to the pandemic. Thus, it is possible as the pandemic subsided, people started to be in the mood again for the holidays, which they could then enjoy without restriction.

## Top songs

```{r}
songs_tf_idf %>% 
  filter(position == 1) %>% 
  group_by(year) %>%
  slice_max(tf_idf, n = 15) %>%
  ungroup() %>% 
  ggplot(aes(tf_idf, reorder(word, tf_idf))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~year, scale = "free") +
  labs(x = "tf-idf", y = NULL)
```

From the sentiment analysis, we learned that the top songs stand out by employing more specific and emotional words. We can learn more about their objects of attention by looking at the top tf-idf values of each song.

The top song in 2019 seems to sing about riding horses on an old town road. This is probably metaphorical for something else, which we can explore later by looking at pairs and groups of words. The song also contains words like "nothing" and "nobody" so there is a possibility that the song means to sing about the state of being alone or different from the rest. Connecting with the previous context on an old town road, perhaps, the singer implies about how they are different now than the people of the place they are from.

Next, in 2020, it seems to be more of a sad song through words like "blinded", "empty", and "drowning". Probable context for "blinded" is "blinded" by the "city's" "lights". Words such as "empty", "drowning", "sleep", "trust" and "touch" could imply a romantic or sensual affair that turned stale.

The top song in 2021 seems, however, to be a more energetic, fun, and positive song with words such as "levitating", "dance", and "blast". Overall, the song seems to simply convey a message about enjoying the "night" "tonight" with "moonlight" and the song connects directly with the listeners by the use of "you're" and invites them on the journey with words like "ride", "fly" and "away".

2022's top song seems to have a summer vibe with top words being "heat", "waves", "june". It is not, however, about enjoying the summer because the words are quite intense and bear some discomforting feelings. The song also sings about "middle" and "nights" where the singer might "sometimes" "think" "about" something and have a "vision".

Finally, 2023 was topped by a seemingly sad song about romance. There is a clear narrative of at least 2 people involved as the song uses a lot of "we" and "our". There is also verbal exchange with words like "telling" and "said". Nostalgia is also a topic of the song with "remember" and this seems to be invoked through "liquor".

# N-grams

We have explored the sentimental and possible themes of the top songs from 2019 to 2023 but the story they tell is still a bit hazy. Pop songs are full of metaphors and employ words in artful ways that cannot be simply deciphered by looking at individual words. In this section, we will look at words of the lyrics in pairs and groups and try to connect them in order to get a fuller picture of the songs. We will first look at pairs of words and the look at groups of 3 words to try to understand better what the songs are singing about.

## Bigram

### Preparing data

```{r}
song_bigram <- songs_cleaned %>%
  select(-lang) %>% 
  #nest back clean dataframe to avoid correcting the spelling again
  nest(lyrics = word) %>% 
  #nest gives a list of list so we have to unlist them
  mutate(lyrics = map(lyrics, unlist),
         lyrics = unlist(lapply(lyrics, paste, collapse = " "))) %>% 
  #unnesting to bigrams 
  unnest_tokens(bigram, lyrics, token = "ngrams", n = 2)

song_bigram %>% 
  count(bigram, sort = TRUE)
```

First to convert words into pairs, we will stitch back the cleaned data frame with individuals words into a data frame with each row representing each column. This is because during the cleaning process, we corrected the spelling of many words and then tokenized the data set. If we were to use the original, uncleaned data set we would have to go through the cleaning process again. Therefore, here the cleaned data frame is stitched back and unraveled into pairs of words, or bigrams.

Looking at the counts, we can see that there are many bigrams that are made up of stop words and vocal sounds that do not contribute much meaning to the songs. Therefore, we will filter them out.

```{r}
bigram_seperated <- song_bigram %>% 
  separate(bigram, c("word1", "word2"), sep = " ")

bigram_filtered <- bigram_seperated %>% 
  #filter stop words
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word) %>% 
  #filter vocal sounds
  filter(!word1 %in% vocal_sounds_extended) %>% 
  filter(!word2 %in% vocal_sounds_extended)

bigram_united <- bigram_filtered %>% 
  unite(bigram, word1, word2, sep = " ")

bigram_united
```

Above, we first separate the bigrams into 2 columns of individual words. We then filtered for each columns of rows that contained the stop words and vocal sounds from the list we created before. We then united the words together to have a final data frame similar to the original but with less meaning less bigrams. Now we can explore better the context of the songs.

```{r}
bigram_united %>% 
  group_by(year) %>% 
  count(bigram, sort = T) %>% 
  slice_max(n, n = 10) %>%
  ungroup() %>% 
  ggplot(aes(n, reorder(bigram, n))) +
  geom_col() +
  facet_wrap(~year, scales = "free_y") +
  xlab("frequency") +
  ylab("word")
```

It seems that for all the years, slang and profanity are frequently present. We can also see why when we performed sentiment analysis, there was a lot of negativity in the songs but in the actual reality and culture that might not be the case. For example, the word "bitch" carries a negative connotation but when paired with "bad", it might not necessarily mean "bad" but rather have a more positive connotation culturally speaking. Overall, there are still many common pairs that do not paint the full meaning of the songs so we will use tf-idf in order to take them out and shift the focus to more relevant words.

### TF-IDF

```{r}
bigram_tf_idf <- bigram_united %>%
  count(year, bigram) %>%
  bind_tf_idf(bigram, year, n) %>%
  arrange(desc(tf_idf))

bigram_tf_idf %>% 
  group_by(year) %>% 
  slice_max(tf_idf, n = 10) %>% 
  ggplot() +
  geom_col(aes(tf_idf, reorder(bigram, tf_idf))) +
  facet_wrap(~year, scale = "free_y")
```

Looking at bigram frequency, we can see some themes similar to the term frequency analysis starting to emerge. Bigrams like "girlfriend girlfriend", " girl summer", "roxanne roxanne", "woman woman", and "broadway girls" indicate that female is a relevant topic for the recent years. Spiritual or religious matter is also important as word pairs like "god's country", " talking god", and " god makes" show up in the charts. It is interesting that in 2021, there are 2 bigrams related to god. Like previously mentioned, the world had just witnessed the havoc of the pandemic, thus, it could be a reason why people are listening to songs related to their faith. We can also see that in 2019, before the pandemic, songs stand out with words talking more about enjoying life and having fun from bigrams such as "whiskey glasses", "girl summer", and "taste tequila". In 2020, there are not many of similar words but rather a new emergence of more sentimental words such as "memories bring" and "feeling feeling". In 2021 and 2022, however, they come back with words like "shaking ass", "knees shaking", and "sigue bailando" (keep dancing).

In order to understand better the relationship and connections of these words, we will map them out into a network and identify clusters that characterize the recent years in music lyrics.

### Graph

```{r}
set.seed(507)

bigram_count <- bigram_filtered %>%
  count(word1, word2 , sort = TRUE)

#prepare graph  
bigram_for_graph <- bigram_count %>%
    filter(n > 8) %>%
    graph_from_data_frame()

#visualise graph
ggraph(bigram_for_graph, layout = "fr") +
    geom_edge_link(aes(edge_alpha = n, edge_width = "1px"), show.legend = FALSE) +
    geom_node_point() +
    geom_node_text(aes(label = name), vjust = 1.5, hjust = 0)
```

From mapping out the connections and relationships of words, we can see a few clusters that could well represent the trending topics in the recent year.

First, there is a cluster around the word "wanna". So, it is common to sing about desires. The word "wanna" also has the strongest connection with the word "feel", which shows that desire for sentiment is possibly most frequent. There is also a cluster around the word "about", the connections are with "thinking", "talking", and "worried". Although they are words that frequently pair with the preposition "about", it is interesting to point out that "thinking" has the highest connection with "about". This closely relates to the theme of desire that we saw before.

There is a dense cluster around the words "bad" and "bitch". Their neighbors are "bitches", "guy", "habits", "lil", and "ass". We discussed before that there is a trending attitude in the pop culture of being a "bad bitch", this cluster seems to confirm this phenomenon with other similar pairs of "bad" and "bitches", "real" and "ass" and "bitch".

We also see a smaller cluster around "love". It is, however, surrounded by more negative words namely "ruin", "savage", and "lies". There is also another small cluster related to this topic formed by the words "heart", "broken", and "cold". We already learned that romance or love is a common topic. Here, we get a more specific picture of how love is sung about, which is more on the sorrow side. It seems that in the recent years, sad love songs are more dominant than happy ones.

The cluster around "girl" also has some interesting connection. "Hot girl summer" was a trending term on social media and it is also present here. The song(s) containing these words perhaps helped popularized it. "baby" is also a prominent word pair for "girl", which is normal as it is a quite common way that some men address at girls. "freaky", however, also seems a strong connection with "girl". Although this might not be direct sexualization but it could be so implicitly. This is a topic that has a long run in history and it seems to persist in the modern day.

Finally, Christmas seems to be many's favorite as we can see some clusters of the relevant words such as "holly", "jolly", "christmas", and "tree", and "jingle", "bell", and "rock". We have picked up this idea before with tf-idf analysis and saw that this seems to have surged in popularity after 2022.

## Trigram

```{r}
song_trigram <- songs_cleaned %>%
  select(-lang) %>% 
  #nest back clean dataframe to avoid correcting the spelling again
  nest(lyrics = word) %>% 
  #nest gives a list of list so we have to unlist them
  mutate(lyrics = map(lyrics, unlist),
         lyrics = unlist(lapply(lyrics, paste, collapse = " "))) %>% 
  #unnesting to bigrams 
  unnest_tokens(trigram, lyrics, token = "ngrams", n = 3)

song_trigram %>% 
  count(trigram, sort = TRUE)
```

Bigram has given us a better context about the songs and shown the story of each year as well as all the years. We can extend the analysis by looking at groups of 3 words, or trigrams, to further understand the context and identify some popular terms being used. The preparation is similar to making bigrams. The cleaned data frame of songs with individual words are stitched back together then re-unraveled into trigrams. From the trigram count, we still need to clean out the vocal sounds to obtain word groups that have meaning.

```{r}
trigram_seperated <- song_trigram %>% 
  separate(trigram, c("word1", "word2", "word3"), sep = " ")

trigram_filtered <- trigram_seperated %>% 
  #filter stop words
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word) %>% 
  filter(!word3 %in% stop_words$word) %>% 
  #filter vocal sounds
  filter(!word1 %in% vocal_sounds_extended) %>% 
  filter(!word2 %in% vocal_sounds_extended) %>% 
  filter(!word3 %in% vocal_sounds_extended) %>% 
  filter(word1!=word2 & word2!=word3 & word1!=word3)

trigram_united <- trigram_filtered %>% 
  unite(trigram, word1, word2, word3, sep = " ")

trigram_united %>% 
  group_by(year) %>% 
  count(trigram, sort = T) %>% 
  slice_max(n, n = 10) %>%
  ungroup() %>% 
  ggplot(aes(n, reorder(trigram, n))) +
  geom_col() +
  facet_wrap(~year, scales = "free_y") +
  xlab("frequency") +
  ylab("word")
```

After filtering out stop words and vocal sounds, we still got many groups of repeating singular word (e.g., "woman woman woman") or repeating pairs (e.g., "jingle bell jingle" from "jingle bell jingle bell"). These groups are extraneous since we examined them in term frequency analysis and bigram analysis. Therefore, we will exclude them and look at groups of different words that might be more interesting for the analysis. The exclusion was done by filtering out rows that have word 1 equal to word 2, word 2 equal to word 3, and word 1 equal to word 3.

In 2019, it seems that some songs with spanish lyrics gained popularity as we see groups of Spanish words. We can also see that the term "hot girl summer" probably started to rise rapidly in popularity from this year. This term seems to be followed up by another song using the term "hot girl bummer" in response in 2020. It also seems that "god" was not exactly used in a context of faith but something else related to drinking as we see the terms "beer talking god", "drinking beer talking", and "talking god amen". Finally, we again see the Christmas terms "holly jolly christmas" rising in 2022 and 2023.

```{r}
trigram_tf_idf <- trigram_united %>%
  count(year, trigram) %>%
  bind_tf_idf(trigram, year, n) %>%
  arrange(desc(tf_idf))

trigram_tf_idf %>% 
  group_by(year) %>% 
  slice_max(tf_idf, n = 10) %>% 
  ggplot() +
  geom_col(aes(tf_idf, reorder(trigram, tf_idf))) +
  facet_wrap(~year, scale = "free_y")
```

Using tf-idf, we obtain similar results with just the term frequency. These word groups seem to be relevant and distinct for each year.

## Top songs

```{r}
bigram_count_top <- bigram_filtered %>%
  filter(position == 1) %>% 
  count(word1, word2 , sort = TRUE)

#prepare graph  
bigram_for_graph_top <- bigram_count_top %>%
    graph_from_data_frame()

#visualise graph
ggraph(bigram_for_graph_top, layout = "fr") +
    geom_edge_link(aes(edge_alpha = n, edge_width = "1px"), show.legend = FALSE) +
    geom_node_point() +
    geom_node_text(aes(label = name), vjust = 1.5, hjust = 0)
```
